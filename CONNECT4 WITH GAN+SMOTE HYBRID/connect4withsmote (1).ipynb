{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":1,"outputs":[{"output_type":"stream","text":"/kaggle/input/connect-4/c4_game_database.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"/kaggle/input/connect-4/c4_game_database.csv\", sep=\",\", header='infer' )\n","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"        pos_01  pos_02  pos_03  pos_04  pos_05  pos_06  pos_07  pos_08  \\\n0          1.0     1.0     1.0    -1.0    -1.0     1.0     0.0    -1.0   \n1          0.0     0.0     1.0     1.0     1.0     1.0     0.0     0.0   \n2          0.0     1.0     0.0     1.0     0.0     0.0     0.0     0.0   \n3          0.0     0.0     0.0     1.0     0.0     0.0     0.0     0.0   \n4          0.0    -1.0    -1.0    -1.0     1.0     0.0     0.0     1.0   \n...        ...     ...     ...     ...     ...     ...     ...     ...   \n376635     0.0     0.0     0.0    -1.0     0.0     0.0     0.0     0.0   \n376636     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n376637     0.0     0.0     1.0     0.0     0.0     1.0     0.0     0.0   \n376638     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n376639     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n\n        pos_09  pos_10  ...  pos_34  pos_35  pos_36  pos_37  pos_38  pos_39  \\\n0         -1.0    -1.0  ...     1.0     1.0    -1.0     1.0    -1.0     1.0   \n1          0.0     1.0  ...    -1.0     1.0     1.0    -1.0    -1.0    -1.0   \n2         -1.0     0.0  ...     0.0    -1.0     1.0    -1.0    -1.0     1.0   \n3          0.0     0.0  ...     0.0     1.0     1.0     1.0    -1.0     1.0   \n4          1.0     1.0  ...     0.0     1.0    -1.0    -1.0     1.0    -1.0   \n...        ...     ...  ...     ...     ...     ...     ...     ...     ...   \n376635     0.0    -1.0  ...     0.0     1.0    -1.0    -1.0    -1.0     1.0   \n376636     0.0    -1.0  ...     0.0     0.0     0.0    -1.0     1.0    -1.0   \n376637     0.0    -1.0  ...     1.0     1.0    -1.0    -1.0    -1.0     1.0   \n376638    -1.0     0.0  ...    -1.0     0.0    -1.0    -1.0     1.0     1.0   \n376639     0.0     0.0  ...    -1.0     0.0    -1.0    -1.0    -1.0     1.0   \n\n        pos_40  pos_41  pos_42  winner  \n0         -1.0     1.0    -1.0    -1.0  \n1          1.0     1.0    -1.0     1.0  \n2         -1.0    -1.0    -1.0    -1.0  \n3         -1.0     0.0     1.0    -1.0  \n4          1.0     0.0    -1.0     1.0  \n...        ...     ...     ...     ...  \n376635    -1.0     0.0     1.0    -1.0  \n376636     1.0     0.0     0.0    -1.0  \n376637     1.0     1.0    -1.0    -1.0  \n376638     1.0    -1.0     0.0    -1.0  \n376639    -1.0     1.0    -1.0     1.0  \n\n[376640 rows x 43 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>pos_01</th>\n      <th>pos_02</th>\n      <th>pos_03</th>\n      <th>pos_04</th>\n      <th>pos_05</th>\n      <th>pos_06</th>\n      <th>pos_07</th>\n      <th>pos_08</th>\n      <th>pos_09</th>\n      <th>pos_10</th>\n      <th>...</th>\n      <th>pos_34</th>\n      <th>pos_35</th>\n      <th>pos_36</th>\n      <th>pos_37</th>\n      <th>pos_38</th>\n      <th>pos_39</th>\n      <th>pos_40</th>\n      <th>pos_41</th>\n      <th>pos_42</th>\n      <th>winner</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>376635</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>376636</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>376637</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>376638</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n    </tr>\n    <tr>\n      <th>376639</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>-1.0</td>\n      <td>0.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n      <td>-1.0</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>376640 rows × 43 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.values[:,0:42].astype(float)\nY = data.values[:,42]","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preX = data[:,0:42]\npreY = data[:,42]\n\n","execution_count":5,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"'(slice(None, None, None), slice(0, 42, None))' is an invalid key","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-02348f478463>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpreY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3022\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3025\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3078\u001b[0m             \u001b[0mcasted_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3079\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3080\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3081\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3082\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), slice(0, 42, None))' is an invalid key"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils import np_utils\n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder = LabelEncoder()\nencoder.fit(Y)\nencoded_Y = encoder.transform(Y)\ndummy_y = np_utils.to_categorical(encoded_Y)","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ysi=pd.Series(encoded_Y) \nysi.value_counts()","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"2    181255\n0    180867\n1     14497\n3        21\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"yk=[]\nfor i in encoded_Y:\n    if i==1:\n        yk.append(1)\n    else:\n        yk.append(0)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ysi=pd.Series(yk) \nysi.value_counts()","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"0    362143\n1     14497\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = np.asarray(yk, dtype=np.float32)\ny.shape","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"(376640,)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\nfrom imblearn.over_sampling import SMOTE\nX_train_res,y_train_res = SMOTE().fit_resample(X_train,y_train)\n\nprint('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))","execution_count":13,"outputs":[{"output_type":"stream","text":"Before OverSampling, counts of label '1': 11562\nBefore OverSampling, counts of label '0': 289750 \n\nAfter OverSampling, the shape of train_X: (579500, 42)\nAfter OverSampling, the shape of train_y: (579500,) \n\nAfter OverSampling, counts of label '1': 289750\nAfter OverSampling, counts of label '0': 289750\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TensorFlow and tf.keras\nimport tensorflow as tf\n\n# Helper libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)\nfrom sklearn.metrics import f1_score\nfrom statistics import stdev","execution_count":14,"outputs":[{"output_type":"stream","text":"2.4.1\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def callf1(xx,yy,xt,yt):\n    model = tf.keras.Sequential([\n        tf.keras.layers.Dense(256, activation='relu'),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(1)\n    ])\n    \n    model.compile(optimizer='adam',\n                  loss='mean_absolute_error',\n                  metrics=['accuracy'])\n    model.fit(xx, yy , epochs=3)\n    ls=[]\n    test_loss, test_acc = model.evaluate(xt,  yt, verbose=2)\n    print('\\nTest accuracy:', test_acc)\n    tr_loss, tr_acc = model.evaluate(xx,  yy, verbose=2)\n    ls.append(test_acc)\n    ls.append(tr_acc)\n    ypr=model.predict(xt)\n    ypr=(ypr>0.5)*1\n    ypre= np.ravel(ypr)\n    ls.append(f1_score(yt, ypre))\n    return ls","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r=callf1(X_train, y_train.ravel(),X_test,y_test.ravel())\n","execution_count":16,"outputs":[{"output_type":"stream","text":"Epoch 1/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0436 - accuracy: 0.9665\nEpoch 2/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0153 - accuracy: 0.9918\nEpoch 3/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0104 - accuracy: 0.9967\n2354/2354 - 3s - loss: 0.0102 - accuracy: 0.9969\n\nTest accuracy: 0.996880292892456\n9416/9416 - 10s - loss: 0.0093 - accuracy: 0.9973\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"r","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"[0.996880292892456, 0.9972752332687378, 0.9614311505005744]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"r=callf1(X_train_res,y_train_res.ravel(),X_test,y_test.ravel())","execution_count":18,"outputs":[{"output_type":"stream","text":"Epoch 1/3\n18110/18110 [==============================] - 37s 2ms/step - loss: 0.0889 - accuracy: 0.9745\nEpoch 2/3\n18110/18110 [==============================] - 38s 2ms/step - loss: 0.0247 - accuracy: 0.9909\nEpoch 3/3\n18110/18110 [==============================] - 39s 2ms/step - loss: 0.0194 - accuracy: 0.9924\n2354/2354 - 2s - loss: 0.0143 - accuracy: 0.9886\n\nTest accuracy: 0.9885965585708618\n18110/18110 - 26s - loss: 0.0184 - accuracy: 0.9941\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"r","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"[0.9885965585708618, 0.9940534830093384, 0.871695294996266]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sta=[]\nste=[]\nsf =[]\nfor i in range(30):\n    r=callf1(X_train, y_train.ravel(),X_test,y_test.ravel())\n    ste.append(r[0])\n    sta.append(r[1])\n    sf.append(r[2])","execution_count":20,"outputs":[{"output_type":"stream","text":"Epoch 1/3\n9416/9416 [==============================] - 21s 2ms/step - loss: 0.0465 - accuracy: 0.9663\nEpoch 2/3\n9416/9416 [==============================] - 20s 2ms/step - loss: 0.0133 - accuracy: 0.9941\nEpoch 3/3\n9416/9416 [==============================] - 20s 2ms/step - loss: 0.0091 - accuracy: 0.9971\n2354/2354 - 2s - loss: 0.0085 - accuracy: 0.9969\n\nTest accuracy: 0.9969068765640259\n9416/9416 - 9s - loss: 0.0076 - accuracy: 0.9977\nEpoch 1/3\n9416/9416 [==============================] - 21s 2ms/step - loss: 0.0447 - accuracy: 0.9651\nEpoch 2/3\n9416/9416 [==============================] - 21s 2ms/step - loss: 0.0162 - accuracy: 0.9907\nEpoch 3/3\n9416/9416 [==============================] - 20s 2ms/step - loss: 0.0122 - accuracy: 0.9952\n2354/2354 - 2s - loss: 0.0119 - accuracy: 0.9958\n\nTest accuracy: 0.9957784414291382\n9416/9416 - 10s - loss: 0.0109 - accuracy: 0.9969\nEpoch 1/3\n9416/9416 [==============================] - 21s 2ms/step - loss: 0.0437 - accuracy: 0.9679\nEpoch 2/3\n9416/9416 [==============================] - 20s 2ms/step - loss: 0.0124 - accuracy: 0.9949\nEpoch 3/3\n9416/9416 [==============================] - 20s 2ms/step - loss: 0.0086 - accuracy: 0.9972\n2354/2354 - 3s - loss: 0.0089 - accuracy: 0.9967\n\nTest accuracy: 0.9966811537742615\n9416/9416 - 9s - loss: 0.0084 - accuracy: 0.9970\nEpoch 1/3\n9416/9416 [==============================] - 21s 2ms/step - loss: 0.0447 - accuracy: 0.9665\nEpoch 2/3\n9416/9416 [==============================] - 20s 2ms/step - loss: 0.0194 - accuracy: 0.9859\nEpoch 3/3\n9416/9416 [==============================] - 20s 2ms/step - loss: 0.0164 - accuracy: 0.9886\n2354/2354 - 2s - loss: 0.0166 - accuracy: 0.9884\n\nTest accuracy: 0.9884239435195923\n9416/9416 - 9s - loss: 0.0158 - accuracy: 0.9893\nEpoch 1/3\n9416/9416 [==============================] - 20s 2ms/step - loss: 0.0454 - accuracy: 0.9670\nEpoch 2/3\n9416/9416 [==============================] - 21s 2ms/step - loss: 0.0194 - accuracy: 0.9858\nEpoch 3/3\n9416/9416 [==============================] - 22s 2ms/step - loss: 0.0165 - accuracy: 0.9886\n2354/2354 - 3s - loss: 0.0156 - accuracy: 0.9884\n\nTest accuracy: 0.9884107112884521\n9416/9416 - 10s - loss: 0.0146 - accuracy: 0.9892\nEpoch 1/3\n9416/9416 [==============================] - 22s 2ms/step - loss: 0.0448 - accuracy: 0.9667\nEpoch 2/3\n9416/9416 [==============================] - 22s 2ms/step - loss: 0.0154 - accuracy: 0.9911\nEpoch 3/3\n9416/9416 [==============================] - 22s 2ms/step - loss: 0.0104 - accuracy: 0.9961\n2354/2354 - 3s - loss: 0.0089 - accuracy: 0.9969\n\nTest accuracy: 0.9968670606613159\n9416/9416 - 11s - loss: 0.0080 - accuracy: 0.9977\nEpoch 1/3\n9416/9416 [==============================] - 27s 3ms/step - loss: 0.0434 - accuracy: 0.9671\nEpoch 2/3\n9416/9416 [==============================] - 22s 2ms/step - loss: 0.0146 - accuracy: 0.9927\nEpoch 3/3\n9416/9416 [==============================] - 22s 2ms/step - loss: 0.0102 - accuracy: 0.9970\n2354/2354 - 3s - loss: 0.0086 - accuracy: 0.9973\n\nTest accuracy: 0.9973183870315552\n9416/9416 - 10s - loss: 0.0079 - accuracy: 0.9979\nEpoch 1/3\n9416/9416 [==============================] - 22s 2ms/step - loss: 0.0444 - accuracy: 0.9656\nEpoch 2/3\n9416/9416 [==============================] - 21s 2ms/step - loss: 0.0155 - accuracy: 0.9912\nEpoch 3/3\n9416/9416 [==============================] - 21s 2ms/step - loss: 0.0121 - accuracy: 0.9951\n2354/2354 - 3s - loss: 0.0112 - accuracy: 0.9953\n\nTest accuracy: 0.9953404068946838\n9416/9416 - 10s - loss: 0.0100 - accuracy: 0.9966\nEpoch 1/3\n9416/9416 [==============================] - 21s 2ms/step - loss: 0.0486 - accuracy: 0.9669\nEpoch 2/3\n9416/9416 [==============================] - 21s 2ms/step - loss: 0.0127 - accuracy: 0.9947\nEpoch 3/3\n9416/9416 [==============================] - 21s 2ms/step - loss: 0.0090 - accuracy: 0.9969\n2354/2354 - 3s - loss: 0.0082 - accuracy: 0.9966\n\nTest accuracy: 0.9966148138046265\n9416/9416 - 10s - loss: 0.0076 - accuracy: 0.9968\nEpoch 1/3\n9416/9416 [==============================] - 21s 2ms/step - loss: 0.0472 - accuracy: 0.9632\nEpoch 2/3\n9416/9416 [==============================] - 21s 2ms/step - loss: 0.0261 - accuracy: 0.9771\nEpoch 3/3\n9416/9416 [==============================] - 21s 2ms/step - loss: 0.0235 - accuracy: 0.9792\n2354/2354 - 2s - loss: 0.0234 - accuracy: 0.9787\n\nTest accuracy: 0.9786931872367859\n9416/9416 - 10s - loss: 0.0224 - accuracy: 0.9796\nEpoch 1/3\n9416/9416 [==============================] - 20s 2ms/step - loss: 0.0436 - accuracy: 0.9666\nEpoch 2/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0130 - accuracy: 0.9944\nEpoch 3/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0098 - accuracy: 0.9971\n2354/2354 - 2s - loss: 0.0095 - accuracy: 0.9969\n\nTest accuracy: 0.996880292892456\n9416/9416 - 9s - loss: 0.0087 - accuracy: 0.9973\nEpoch 1/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0433 - accuracy: 0.9664\nEpoch 2/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0196 - accuracy: 0.9861\nEpoch 3/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0167 - accuracy: 0.9888\n2354/2354 - 2s - loss: 0.0165 - accuracy: 0.9883\n\nTest accuracy: 0.9882646799087524\n9416/9416 - 9s - loss: 0.0154 - accuracy: 0.9893\nEpoch 1/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0467 - accuracy: 0.9663\nEpoch 2/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0140 - accuracy: 0.9933\nEpoch 3/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0104 - accuracy: 0.9966\n2354/2354 - 2s - loss: 0.0088 - accuracy: 0.9970\n\nTest accuracy: 0.9970396161079407\n9416/9416 - 9s - loss: 0.0079 - accuracy: 0.9976\nEpoch 1/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0449 - accuracy: 0.9660\nEpoch 2/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0145 - accuracy: 0.9927\nEpoch 3/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0105 - accuracy: 0.9967\n2354/2354 - 2s - loss: 0.0087 - accuracy: 0.9971\n\nTest accuracy: 0.9970794320106506\n9416/9416 - 9s - loss: 0.0078 - accuracy: 0.9978\nEpoch 1/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0439 - accuracy: 0.9653\nEpoch 2/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0197 - accuracy: 0.9856\nEpoch 3/3\n9416/9416 [==============================] - 17s 2ms/step - loss: 0.0165 - accuracy: 0.9887\n2354/2354 - 2s - loss: 0.0163 - accuracy: 0.9883\n\nTest accuracy: 0.9882646799087524\n9416/9416 - 8s - loss: 0.0153 - accuracy: 0.9889\nEpoch 1/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0451 - accuracy: 0.9648\nEpoch 2/3\n9416/9416 [==============================] - 17s 2ms/step - loss: 0.0263 - accuracy: 0.9771\nEpoch 3/3\n9416/9416 [==============================] - 17s 2ms/step - loss: 0.0234 - accuracy: 0.9795\n2354/2354 - 2s - loss: 0.0238 - accuracy: 0.9788\n\nTest accuracy: 0.9787861108779907\n9416/9416 - 8s - loss: 0.0229 - accuracy: 0.9795\nEpoch 1/3\n9416/9416 [==============================] - 17s 2ms/step - loss: 0.0461 - accuracy: 0.9647\nEpoch 2/3\n9416/9416 [==============================] - 17s 2ms/step - loss: 0.0263 - accuracy: 0.9773\nEpoch 3/3\n9416/9416 [==============================] - 17s 2ms/step - loss: 0.0236 - accuracy: 0.9789\n2354/2354 - 2s - loss: 0.0234 - accuracy: 0.9789\n\nTest accuracy: 0.9788525104522705\n9416/9416 - 9s - loss: 0.0226 - accuracy: 0.9795\nEpoch 1/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0472 - accuracy: 0.9629\nEpoch 2/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0188 - accuracy: 0.9876\nEpoch 3/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0113 - accuracy: 0.9965\n2354/2354 - 2s - loss: 0.0097 - accuracy: 0.9969\n\nTest accuracy: 0.996893584728241\n9416/9416 - 9s - loss: 0.0086 - accuracy: 0.9977\nEpoch 1/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0446 - accuracy: 0.9664\nEpoch 2/3\n9416/9416 [==============================] - 20s 2ms/step - loss: 0.0193 - accuracy: 0.9865\nEpoch 3/3\n","name":"stdout"},{"output_type":"stream","text":"9416/9416 [==============================] - 20s 2ms/step - loss: 0.0166 - accuracy: 0.9887\n2354/2354 - 3s - loss: 0.0164 - accuracy: 0.9885\n\nTest accuracy: 0.9884505271911621\n9416/9416 - 9s - loss: 0.0153 - accuracy: 0.9893\nEpoch 1/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0444 - accuracy: 0.9677\nEpoch 2/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0135 - accuracy: 0.9937\nEpoch 3/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0092 - accuracy: 0.9970\n2354/2354 - 2s - loss: 0.0075 - accuracy: 0.9973\n\nTest accuracy: 0.9973316788673401\n9416/9416 - 9s - loss: 0.0066 - accuracy: 0.9978\nEpoch 1/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0461 - accuracy: 0.9663\nEpoch 2/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0190 - accuracy: 0.9861\nEpoch 3/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0160 - accuracy: 0.9887\n2354/2354 - 2s - loss: 0.0154 - accuracy: 0.9883\n\nTest accuracy: 0.9882779121398926\n9416/9416 - 9s - loss: 0.0143 - accuracy: 0.9891\nEpoch 1/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0439 - accuracy: 0.9663\nEpoch 2/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0205 - accuracy: 0.9850\nEpoch 3/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0175 - accuracy: 0.9880\n2354/2354 - 2s - loss: 0.0180 - accuracy: 0.9877\n\nTest accuracy: 0.9876672625541687\n9416/9416 - 9s - loss: 0.0166 - accuracy: 0.9890\nEpoch 1/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0455 - accuracy: 0.9649\nEpoch 2/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0260 - accuracy: 0.9771\nEpoch 3/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0239 - accuracy: 0.9795\n2354/2354 - 2s - loss: 0.0240 - accuracy: 0.9786\n\nTest accuracy: 0.9785869717597961\n9416/9416 - 9s - loss: 0.0230 - accuracy: 0.9794\nEpoch 1/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0462 - accuracy: 0.9648\nEpoch 2/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0196 - accuracy: 0.9857\nEpoch 3/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0164 - accuracy: 0.9886\n2354/2354 - 2s - loss: 0.0163 - accuracy: 0.9886\n\nTest accuracy: 0.9886230826377869\n9416/9416 - 9s - loss: 0.0155 - accuracy: 0.9893\nEpoch 1/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0484 - accuracy: 0.9673\nEpoch 2/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0127 - accuracy: 0.9950\nEpoch 3/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0092 - accuracy: 0.9972\n2354/2354 - 2s - loss: 0.0079 - accuracy: 0.9968\n\nTest accuracy: 0.9968404769897461\n9416/9416 - 8s - loss: 0.0073 - accuracy: 0.9972\nEpoch 1/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0455 - accuracy: 0.9655\nEpoch 2/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0210 - accuracy: 0.9838\nEpoch 3/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0178 - accuracy: 0.9868\n2354/2354 - 2s - loss: 0.0168 - accuracy: 0.9871\n\nTest accuracy: 0.9871097207069397\n9416/9416 - 9s - loss: 0.0161 - accuracy: 0.9876\nEpoch 1/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0454 - accuracy: 0.9647\nEpoch 2/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0141 - accuracy: 0.9931\nEpoch 3/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0087 - accuracy: 0.9970\n2354/2354 - 2s - loss: 0.0079 - accuracy: 0.9970\n\nTest accuracy: 0.9969865083694458\n9416/9416 - 8s - loss: 0.0067 - accuracy: 0.9980\nEpoch 1/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0446 - accuracy: 0.9659\nEpoch 2/3\n9416/9416 [==============================] - 22s 2ms/step - loss: 0.0196 - accuracy: 0.9860\nEpoch 3/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0169 - accuracy: 0.9886\n2354/2354 - 3s - loss: 0.0166 - accuracy: 0.9883\n\nTest accuracy: 0.9882779121398926\n9416/9416 - 9s - loss: 0.0155 - accuracy: 0.9893\nEpoch 1/3\n9416/9416 [==============================] - 20s 2ms/step - loss: 0.0485 - accuracy: 0.9674 0s - loss: 0.0487 \nEpoch 2/3\n9416/9416 [==============================] - 20s 2ms/step - loss: 0.0144 - accuracy: 0.9932\nEpoch 3/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0108 - accuracy: 0.9962\n2354/2354 - 2s - loss: 0.0089 - accuracy: 0.9969\n\nTest accuracy: 0.9969334006309509\n9416/9416 - 8s - loss: 0.0081 - accuracy: 0.9977\nEpoch 1/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0453 - accuracy: 0.9654\nEpoch 2/3\n9416/9416 [==============================] - 18s 2ms/step - loss: 0.0196 - accuracy: 0.9861\nEpoch 3/3\n9416/9416 [==============================] - 19s 2ms/step - loss: 0.0157 - accuracy: 0.9888\n2354/2354 - 2s - loss: 0.0149 - accuracy: 0.9885\n\nTest accuracy: 0.988530158996582\n9416/9416 - 9s - loss: 0.0139 - accuracy: 0.9894\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(sf)/30","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"0.870461938309295"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(sta)/30","execution_count":54,"outputs":[{"output_type":"execute_result","execution_count":54,"data":{"text/plain":"0.9919766485691071"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(ste)/30","execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"0.9912237167358399"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max(sf)","execution_count":56,"outputs":[{"output_type":"execute_result","execution_count":56,"data":{"text/plain":"0.9666279262825834"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max(sta)","execution_count":57,"outputs":[{"output_type":"execute_result","execution_count":57,"data":{"text/plain":"0.9980219602584839"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max(ste)","execution_count":58,"outputs":[{"output_type":"execute_result","execution_count":58,"data":{"text/plain":"0.9973316788673401"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"stdev(sf)","execution_count":59,"outputs":[{"output_type":"execute_result","execution_count":59,"data":{"text/plain":"0.1088255843443249"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"stdev(sta)","execution_count":60,"outputs":[{"output_type":"execute_result","execution_count":60,"data":{"text/plain":"0.006358599070000213"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"stdev(ste)","execution_count":61,"outputs":[{"output_type":"execute_result","execution_count":61,"data":{"text/plain":"0.0064087721073586195"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sta2=[]\nste2=[]\nsf2 =[]\nfor i in range(30):\n    r=callf1(X_train_res,y_train_res.ravel(),X_test,y_test.ravel())\n    ste2.append(r[0])\n    sta2.append(r[1])\n    sf2.append(r[2])","execution_count":22,"outputs":[{"output_type":"stream","text":"Epoch 1/3\n18110/18110 [==============================] - 38s 2ms/step - loss: 0.0878 - accuracy: 0.9733\nEpoch 2/3\n18110/18110 [==============================] - 37s 2ms/step - loss: 0.0239 - accuracy: 0.9912\nEpoch 3/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0192 - accuracy: 0.9924\n2354/2354 - 2s - loss: 0.0151 - accuracy: 0.9879\n\nTest accuracy: 0.9879460334777832\n18110/18110 - 25s - loss: 0.0247 - accuracy: 0.9936\nEpoch 1/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0871 - accuracy: 0.9708\nEpoch 2/3\n18110/18110 [==============================] - 37s 2ms/step - loss: 0.0248 - accuracy: 0.9913\nEpoch 3/3\n18110/18110 [==============================] - 40s 2ms/step - loss: 0.0205 - accuracy: 0.9929\n2354/2354 - 2s - loss: 0.0131 - accuracy: 0.9892\n\nTest accuracy: 0.9892072081565857\n18110/18110 - 25s - loss: 0.0169 - accuracy: 0.9945\nEpoch 1/3\n18110/18110 [==============================] - 40s 2ms/step - loss: 0.0911 - accuracy: 0.9725\nEpoch 2/3\n18110/18110 [==============================] - 41s 2ms/step - loss: 0.0249 - accuracy: 0.9908\nEpoch 3/3\n18110/18110 [==============================] - 40s 2ms/step - loss: 0.0192 - accuracy: 0.9928\n2354/2354 - 2s - loss: 0.0124 - accuracy: 0.9894\n\nTest accuracy: 0.9894461631774902\n18110/18110 - 27s - loss: 0.0153 - accuracy: 0.9944\nEpoch 1/3\n18110/18110 [==============================] - 41s 2ms/step - loss: 0.0912 - accuracy: 0.9731\nEpoch 2/3\n18110/18110 [==============================] - 39s 2ms/step - loss: 0.0244 - accuracy: 0.9911\nEpoch 3/3\n18110/18110 [==============================] - 40s 2ms/step - loss: 0.0190 - accuracy: 0.9925\n2354/2354 - 2s - loss: 0.0162 - accuracy: 0.9869\n\nTest accuracy: 0.9869371056556702\n18110/18110 - 26s - loss: 0.0180 - accuracy: 0.9937\nEpoch 1/3\n18110/18110 [==============================] - 40s 2ms/step - loss: 0.0896 - accuracy: 0.9712\nEpoch 2/3\n18110/18110 [==============================] - 39s 2ms/step - loss: 0.0242 - accuracy: 0.9911\nEpoch 3/3\n18110/18110 [==============================] - 39s 2ms/step - loss: 0.0194 - accuracy: 0.9926\n2354/2354 - 2s - loss: 0.0166 - accuracy: 0.9860\n\nTest accuracy: 0.9860343933105469\n18110/18110 - 25s - loss: 0.0167 - accuracy: 0.9934\nEpoch 1/3\n18110/18110 [==============================] - 40s 2ms/step - loss: 0.0915 - accuracy: 0.9706\nEpoch 2/3\n18110/18110 [==============================] - 40s 2ms/step - loss: 0.0246 - accuracy: 0.9907\nEpoch 3/3\n18110/18110 [==============================] - 40s 2ms/step - loss: 0.0195 - accuracy: 0.9923\n2354/2354 - 2s - loss: 0.0149 - accuracy: 0.9883\n\nTest accuracy: 0.9882779121398926\n18110/18110 - 26s - loss: 0.0239 - accuracy: 0.9938\nEpoch 1/3\n18110/18110 [==============================] - 40s 2ms/step - loss: 0.0903 - accuracy: 0.9731\nEpoch 2/3\n18110/18110 [==============================] - 41s 2ms/step - loss: 0.0253 - accuracy: 0.9908\nEpoch 3/3\n18110/18110 [==============================] - 39s 2ms/step - loss: 0.0200 - accuracy: 0.9925\n2354/2354 - 2s - loss: 0.0146 - accuracy: 0.9881\n\nTest accuracy: 0.9881318807601929\n18110/18110 - 26s - loss: 0.0196 - accuracy: 0.9941\nEpoch 1/3\n18110/18110 [==============================] - 40s 2ms/step - loss: 0.0887 - accuracy: 0.9727\nEpoch 2/3\n18110/18110 [==============================] - 39s 2ms/step - loss: 0.0246 - accuracy: 0.9911\nEpoch 3/3\n18110/18110 [==============================] - 40s 2ms/step - loss: 0.0197 - accuracy: 0.9928\n2354/2354 - 2s - loss: 0.0130 - accuracy: 0.9891\n\nTest accuracy: 0.989061176776886\n18110/18110 - 26s - loss: 0.0157 - accuracy: 0.9943\nEpoch 1/3\n18110/18110 [==============================] - 40s 2ms/step - loss: 0.0921 - accuracy: 0.9728\nEpoch 2/3\n18110/18110 [==============================] - 38s 2ms/step - loss: 0.0258 - accuracy: 0.9911\nEpoch 3/3\n18110/18110 [==============================] - 38s 2ms/step - loss: 0.0197 - accuracy: 0.9930\n2354/2354 - 2s - loss: 0.0153 - accuracy: 0.9871\n\nTest accuracy: 0.9870699048042297\n18110/18110 - 26s - loss: 0.0171 - accuracy: 0.9937\nEpoch 1/3\n18110/18110 [==============================] - 39s 2ms/step - loss: 0.0913 - accuracy: 0.9713\nEpoch 2/3\n18110/18110 [==============================] - 40s 2ms/step - loss: 0.0244 - accuracy: 0.9911\nEpoch 3/3\n18110/18110 [==============================] - 38s 2ms/step - loss: 0.0185 - accuracy: 0.9928\n2354/2354 - 3s - loss: 0.0155 - accuracy: 0.9872\n\nTest accuracy: 0.9872159361839294\n18110/18110 - 26s - loss: 0.0194 - accuracy: 0.9940\nEpoch 1/3\n18110/18110 [==============================] - 37s 2ms/step - loss: 0.0897 - accuracy: 0.9700\nEpoch 2/3\n18110/18110 [==============================] - 37s 2ms/step - loss: 0.0248 - accuracy: 0.9914\nEpoch 3/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0201 - accuracy: 0.9932\n2354/2354 - 2s - loss: 0.0127 - accuracy: 0.9903\n\nTest accuracy: 0.9903223514556885\n18110/18110 - 24s - loss: 0.0174 - accuracy: 0.9943\nEpoch 1/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0896 - accuracy: 0.9718\nEpoch 2/3\n18110/18110 [==============================] - 38s 2ms/step - loss: 0.0255 - accuracy: 0.9913\nEpoch 3/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0199 - accuracy: 0.9928\n2354/2354 - 2s - loss: 0.0140 - accuracy: 0.9884\n\nTest accuracy: 0.9883974194526672\n18110/18110 - 25s - loss: 0.0172 - accuracy: 0.9941\nEpoch 1/3\n18110/18110 [==============================] - 38s 2ms/step - loss: 0.0913 - accuracy: 0.9719\nEpoch 2/3\n18110/18110 [==============================] - 37s 2ms/step - loss: 0.0248 - accuracy: 0.9909\nEpoch 3/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0187 - accuracy: 0.9926\n2354/2354 - 2s - loss: 0.0145 - accuracy: 0.9878\n\nTest accuracy: 0.9877734780311584\n18110/18110 - 25s - loss: 0.0158 - accuracy: 0.9938\nEpoch 1/3\n18110/18110 [==============================] - 37s 2ms/step - loss: 0.0920 - accuracy: 0.9721\nEpoch 2/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0249 - accuracy: 0.9912\nEpoch 3/3\n18110/18110 [==============================] - 37s 2ms/step - loss: 0.0193 - accuracy: 0.9927\n2354/2354 - 2s - loss: 0.0148 - accuracy: 0.9875\n\nTest accuracy: 0.9875345230102539\n18110/18110 - 24s - loss: 0.0150 - accuracy: 0.9938\nEpoch 1/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0905 - accuracy: 0.9727\nEpoch 2/3\n18110/18110 [==============================] - 37s 2ms/step - loss: 0.0247 - accuracy: 0.9909\nEpoch 3/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0192 - accuracy: 0.9926\n2354/2354 - 2s - loss: 0.0154 - accuracy: 0.9870\n\nTest accuracy: 0.9869503974914551\n18110/18110 - 25s - loss: 0.0167 - accuracy: 0.9935\nEpoch 1/3\n18110/18110 [==============================] - ETA: 0s - loss: 0.0907 - accuracy: 0.97 - 36s 2ms/step - loss: 0.0906 - accuracy: 0.9716\nEpoch 2/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0245 - accuracy: 0.9913\nEpoch 3/3\n18110/18110 [==============================] - 41s 2ms/step - loss: 0.0194 - accuracy: 0.9928\n2354/2354 - 2s - loss: 0.0148 - accuracy: 0.9879\n\nTest accuracy: 0.9879062175750732\n18110/18110 - 24s - loss: 0.0186 - accuracy: 0.9937\nEpoch 1/3\n18110/18110 [==============================] - 35s 2ms/step - loss: 0.0886 - accuracy: 0.9722\nEpoch 2/3\n18110/18110 [==============================] - 35s 2ms/step - loss: 0.0242 - accuracy: 0.9911\nEpoch 3/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0192 - accuracy: 0.9926\n2354/2354 - 2s - loss: 0.0162 - accuracy: 0.9862\n\nTest accuracy: 0.9861671328544617\n18110/18110 - 24s - loss: 0.0171 - accuracy: 0.9934\nEpoch 1/3\n18110/18110 [==============================] - 35s 2ms/step - loss: 0.0913 - accuracy: 0.9690\nEpoch 2/3\n18110/18110 [==============================] - 35s 2ms/step - loss: 0.0260 - accuracy: 0.9910\nEpoch 3/3\n18110/18110 [==============================] - 34s 2ms/step - loss: 0.0178 - accuracy: 0.9934\n2354/2354 - 2s - loss: 0.0132 - accuracy: 0.9894\n\nTest accuracy: 0.9894461631774902\n18110/18110 - 24s - loss: 0.0163 - accuracy: 0.9939\nEpoch 1/3\n","name":"stdout"},{"output_type":"stream","text":"18110/18110 [==============================] - 35s 2ms/step - loss: 0.0917 - accuracy: 0.9732\nEpoch 2/3\n18110/18110 [==============================] - 34s 2ms/step - loss: 0.0234 - accuracy: 0.9912\nEpoch 3/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0177 - accuracy: 0.9931\n2354/2354 - 2s - loss: 0.0135 - accuracy: 0.9886\n\nTest accuracy: 0.9886363744735718\n18110/18110 - 25s - loss: 0.0177 - accuracy: 0.9941\nEpoch 1/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0881 - accuracy: 0.9701\nEpoch 2/3\n18110/18110 [==============================] - 35s 2ms/step - loss: 0.0242 - accuracy: 0.9908\nEpoch 3/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0198 - accuracy: 0.9925\n2354/2354 - 2s - loss: 0.0149 - accuracy: 0.9879\n\nTest accuracy: 0.9878664016723633\n18110/18110 - 24s - loss: 0.0177 - accuracy: 0.9934\nEpoch 1/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0909 - accuracy: 0.9716\nEpoch 2/3\n18110/18110 [==============================] - 37s 2ms/step - loss: 0.0245 - accuracy: 0.9908\nEpoch 3/3\n18110/18110 [==============================] - 37s 2ms/step - loss: 0.0190 - accuracy: 0.9928\n2354/2354 - 2s - loss: 0.0155 - accuracy: 0.9871\n\nTest accuracy: 0.9870831370353699\n18110/18110 - 25s - loss: 0.0157 - accuracy: 0.9935\nEpoch 1/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0914 - accuracy: 0.9724\nEpoch 2/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0248 - accuracy: 0.9910\nEpoch 3/3\n18110/18110 [==============================] - 36s 2ms/step - loss: 0.0199 - accuracy: 0.9928\n2354/2354 - 2s - loss: 0.0149 - accuracy: 0.9882\n\nTest accuracy: 0.9881849884986877\n18110/18110 - 25s - loss: 0.0216 - accuracy: 0.9941\nEpoch 1/3\n18110/18110 [==============================] - 38s 2ms/step - loss: 0.0883 - accuracy: 0.9720\nEpoch 2/3\n18110/18110 [==============================] - 37s 2ms/step - loss: 0.0248 - accuracy: 0.9911\nEpoch 3/3\n18110/18110 [==============================] - 37s 2ms/step - loss: 0.0202 - accuracy: 0.9927\n2354/2354 - 2s - loss: 0.0136 - accuracy: 0.9896\n\nTest accuracy: 0.989578902721405\n18110/18110 - 26s - loss: 0.0191 - accuracy: 0.9940\nEpoch 1/3\n18110/18110 [==============================] - 38s 2ms/step - loss: 0.0935 - accuracy: 0.9724\nEpoch 2/3\n18110/18110 [==============================] - 38s 2ms/step - loss: 0.0256 - accuracy: 0.9908\nEpoch 3/3\n18110/18110 [==============================] - 39s 2ms/step - loss: 0.0182 - accuracy: 0.9928\n2354/2354 - 2s - loss: 0.0150 - accuracy: 0.9876\n\nTest accuracy: 0.9875743389129639\n18110/18110 - 25s - loss: 0.0160 - accuracy: 0.9937\nEpoch 1/3\n18110/18110 [==============================] - 38s 2ms/step - loss: 0.0890 - accuracy: 0.9689\nEpoch 2/3\n18110/18110 [==============================] - 38s 2ms/step - loss: 0.0243 - accuracy: 0.9913\nEpoch 3/3\n18110/18110 [==============================] - 38s 2ms/step - loss: 0.0195 - accuracy: 0.9925\n2354/2354 - 2s - loss: 0.0168 - accuracy: 0.9858\n\nTest accuracy: 0.9858087301254272\n18110/18110 - 26s - loss: 0.0182 - accuracy: 0.9931\nEpoch 1/3\n18110/18110 [==============================] - 38s 2ms/step - loss: 0.0887 - accuracy: 0.9629\nEpoch 2/3\n18110/18110 [==============================] - 39s 2ms/step - loss: 0.0258 - accuracy: 0.9902\nEpoch 3/3\n18110/18110 [==============================] - 38s 2ms/step - loss: 0.0194 - accuracy: 0.9924\n2354/2354 - 3s - loss: 0.0163 - accuracy: 0.9871\n\nTest accuracy: 0.9870831370353699\n18110/18110 - 27s - loss: 0.0171 - accuracy: 0.9927\nEpoch 1/3\n18110/18110 [==============================] - 40s 2ms/step - loss: 0.0884 - accuracy: 0.9709\nEpoch 2/3\n18110/18110 [==============================] - 39s 2ms/step - loss: 0.0245 - accuracy: 0.9912\nEpoch 3/3\n18110/18110 [==============================] - 39s 2ms/step - loss: 0.0194 - accuracy: 0.9925\n2354/2354 - 3s - loss: 0.0139 - accuracy: 0.9886\n\nTest accuracy: 0.9886363744735718\n18110/18110 - 27s - loss: 0.0163 - accuracy: 0.9940\nEpoch 1/3\n18110/18110 [==============================] - 46s 3ms/step - loss: 0.0874 - accuracy: 0.9714\nEpoch 2/3\n18110/18110 [==============================] - 39s 2ms/step - loss: 0.0250 - accuracy: 0.9907\nEpoch 3/3\n18110/18110 [==============================] - 39s 2ms/step - loss: 0.0192 - accuracy: 0.9925\n2354/2354 - 2s - loss: 0.0164 - accuracy: 0.9858\n\nTest accuracy: 0.9857954382896423\n18110/18110 - 27s - loss: 0.0166 - accuracy: 0.9934\nEpoch 1/3\n18110/18110 [==============================] - 42s 2ms/step - loss: 0.0873 - accuracy: 0.9726\nEpoch 2/3\n18110/18110 [==============================] - 39s 2ms/step - loss: 0.0232 - accuracy: 0.9914\nEpoch 3/3\n18110/18110 [==============================] - 39s 2ms/step - loss: 0.0175 - accuracy: 0.9932\n2354/2354 - 3s - loss: 0.0139 - accuracy: 0.9883\n\nTest accuracy: 0.9882646799087524\n18110/18110 - 27s - loss: 0.0155 - accuracy: 0.9942\nEpoch 1/3\n18110/18110 [==============================] - 40s 2ms/step - loss: 0.0884 - accuracy: 0.9708\nEpoch 2/3\n18110/18110 [==============================] - 39s 2ms/step - loss: 0.0250 - accuracy: 0.9913\nEpoch 3/3\n18110/18110 [==============================] - 40s 2ms/step - loss: 0.0196 - accuracy: 0.9927\n2354/2354 - 2s - loss: 0.0143 - accuracy: 0.9881\n\nTest accuracy: 0.9881318807601929\n18110/18110 - 27s - loss: 0.0149 - accuracy: 0.9940\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(sf2)/30","execution_count":53,"outputs":[{"output_type":"execute_result","execution_count":53,"data":{"text/plain":"0.8649004755554831"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max(sf2)","execution_count":62,"outputs":[{"output_type":"execute_result","execution_count":62,"data":{"text/plain":"0.8887871853546911"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"stdev(sf2)","execution_count":63,"outputs":[{"output_type":"execute_result","execution_count":63,"data":{"text/plain":"0.010995605820524905"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(ste2)/30","execution_count":64,"outputs":[{"output_type":"execute_result","execution_count":64,"data":{"text/plain":"0.9878823260466257"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max(ste2)","execution_count":65,"outputs":[{"output_type":"execute_result","execution_count":65,"data":{"text/plain":"0.9903223514556885"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"stdev(ste2)","execution_count":66,"outputs":[{"output_type":"execute_result","execution_count":66,"data":{"text/plain":"0.0011473695983580364"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum(sta2)/30","execution_count":67,"outputs":[{"output_type":"execute_result","execution_count":67,"data":{"text/plain":"0.9938056965668997"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"max(sta2)","execution_count":68,"outputs":[{"output_type":"execute_result","execution_count":68,"data":{"text/plain":"0.9945073127746582"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"stdev(sta2)","execution_count":69,"outputs":[{"output_type":"execute_result","execution_count":69,"data":{"text/plain":"0.00040409229572709867"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"save=1","execution_count":72,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"progress=1","execution_count":73,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save2=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}