{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"urlist=['https://raw.githubusercontent.com/sydney-machine-learning/GANclassimbalanced/main/DATASETS/page-blocks-1-3_vs_4.dat','https://raw.githubusercontent.com/sydney-machine-learning/GANclassimbalanced/main/DATASETS/ecoli4.dat','https://raw.githubusercontent.com/sydney-machine-learning/GANclassimbalanced/main/DATASETS/poker-8_vs_6.dat','https://raw.githubusercontent.com/sydney-machine-learning/GANclassimbalanced/main/DATASETS/winequality-red-8_vs_6.dat','https://raw.githubusercontent.com/sydney-machine-learning/GANclassimbalanced/main/DATASETS/yeast-2_vs_4.dat']\noption=int(input(\"Enter 0 for page-blocks\\nEnter 1 for ecoli\\nEnter 2 for poker\\nEnter 3 for winequality\\nEnter 4 for yeast\\n\"))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nurl=urlist[option]\ndata = pd.read_csv(url, sep=\",\", header='infer' )\ndata","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t=()\nt=data.shape\nX = data.values[:,0:(t[1]-1)].astype(float)\nY = data.values[:,(t[1]-1)]\nprint(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if option==0 or option==3 or option==2 :\n    from sklearn.preprocessing import MinMaxScaler\n    scaler = MinMaxScaler()\n    X = scaler.fit_transform(X)\n    print(X)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils import np_utils\nencoder = LabelEncoder()\nencoder.fit(Y)\nencoded_Y = encoder.transform(Y)\ndummy_y = np_utils.to_categorical(encoded_Y)\nysi=pd.Series(encoded_Y) \nysi.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if option==1:\n    yk=[]\n    for i in encoded_Y:\n        if i==2:\n            yk.append(1)\n        else:\n            yk.append(0)\n    encoded_Y = np.asarray(yk, dtype=np.float32)\n    encoded_Y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if option==0:\n    rs=1\n    ep=10\n    ne=2000\nif option==1:\n    rs=0\n    ep=10\n    ne=700\nif option==2:\n    rs=1\n    ep=30\n    ne=1500\nif option==3:\n    rs=4\n    ep=30\n    ne=1500    \nif option==4:\n    rs=1\n    ep=10\n    ne=1000    \n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X,encoded_Y, test_size=0.2, random_state=rs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train==1)))\nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train==0)))\nfrom imblearn.over_sampling import SMOTE\nX_train_res,y_train_res = SMOTE().fit_resample(X_train,y_train)\n\nprint('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res==0)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)\nfrom sklearn.metrics import f1_score\nfrom statistics import stdev","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def callf1(xx,yy,xt,yt):\n    model = tf.keras.Sequential([\n        tf.keras.layers.Dense(256, activation='relu'),\n        tf.keras.layers.Dense(128, activation='relu'),\n        tf.keras.layers.Dense(1)\n    ])\n    \n    model.compile(optimizer='adam',\n                  loss='mean_absolute_error',\n                  metrics=['accuracy'])\n    model.fit(xx, yy , epochs=ep)\n    ls=[]\n    test_loss, test_acc = model.evaluate(xt,  yt, verbose=2)\n    print('\\nTest accuracy:', test_acc)\n    tr_loss, tr_acc = model.evaluate(xx,  yy, verbose=2)\n    ls.append(test_acc)\n    ls.append(tr_acc)\n    ypr=model.predict(xt)\n    ypr=(ypr>0.5)*1\n    ypre= np.ravel(ypr)\n    ls.append(f1_score(yt, ypre))\n    return ls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sta=[]\nste=[]\nsf =[]\nfor i in range(30):\n    r=callf1(X_train, y_train.ravel(),X_test,y_test.ravel())\n    ste.append(r[0])\n    sta.append(r[1])\n    sf.append(r[2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(sf)/30","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(sta)/30","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(ste)/30","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(sf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(sta)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(ste)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stdev(sf)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stdev(sta)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stdev(ste)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sta2=[]\nste2=[]\nsf2 =[]\nfor i in range(30):\n    r=callf1(X_train_res,y_train_res.ravel(),X_test,y_test.ravel())\n    ste2.append(r[0])\n    sta2.append(r[1])\n    sf2.append(r[2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(sf2)/30","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(sta2)/30","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(ste2)/30","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(sf2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(sta2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(ste2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stdev(sf2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stdev(sta2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stdev(ste2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t2=X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_oversampled=X_train_res[(t2[0]):]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom tqdm.auto import tqdm\nfrom torchvision import transforms\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_generator_block(input_dim, output_dim):\n    return nn.Sequential(\n        nn.Linear(input_dim, output_dim),\n        nn.BatchNorm1d(output_dim),\n        nn.ReLU(inplace=True),\n    )\nclass Generator(nn.Module):\n\n    def __init__(self, z_dim=t2[1], im_dim=t2[1], hidden_dim=128):\n        super(Generator, self).__init__()\n        self.gen = nn.Sequential(\n            get_generator_block(z_dim, hidden_dim),\n            get_generator_block(hidden_dim, hidden_dim * 2),\n            get_generator_block(hidden_dim * 2, hidden_dim * 4),\n            get_generator_block(hidden_dim * 4, hidden_dim * 8),\n            nn.Linear(hidden_dim * 8, im_dim),\n            nn.Sigmoid()\n        )\n    def forward(self, noise):\n        return self.gen(noise)\n    \n    # Needed for grading\n    def get_gen(self):\n\n        return self.gen\ndef get_discriminator_block(input_dim, output_dim):\n    return nn.Sequential(\n        nn.Linear(input_dim, output_dim),\n        nn.LeakyReLU(0.2, inplace=True)        \n    )\nclass Discriminator(nn.Module):\n    def __init__(self, im_dim=t2[1], hidden_dim=128):\n        super(Discriminator, self).__init__()\n        self.disc = nn.Sequential(\n            get_discriminator_block(im_dim, hidden_dim * 4),\n            get_discriminator_block(hidden_dim * 4, hidden_dim * 2),\n            get_discriminator_block(hidden_dim * 2, hidden_dim),\n            nn.Linear(hidden_dim, 1)\n        )\n\n    def forward(self, image):\n\n        return self.disc(image)\n    \n    def get_disc(self):\n\n        return self.dis\nX_oversampled = torch.from_numpy(X_oversampled)\ncriterion = nn.BCEWithLogitsLoss()\nn_epochs = ne\nz_dim = t2[1]\nbatch_size = 128\nlr = 0.00001\ndisplay_step = 1\ndevice = 'cuda'\ngen = Generator(z_dim).to(device)\ngen_opt = torch.optim.Adam(gen.parameters(), lr=lr)\ndisc = Discriminator().to(device) \ndisc_opt = torch.optim.Adam(disc.parameters(), lr=lr)\ndef get_disc_loss(gen, disc, criterion, real, device):\n\n    fake = gen(X_oversampled.float().to(device))\n    disc_fake_pred = disc(fake.detach())\n    disc_fake_loss = criterion(disc_fake_pred, torch.zeros_like(disc_fake_pred))\n    disc_real_pred = disc(real)\n    disc_real_loss = criterion(disc_real_pred, torch.ones_like(disc_real_pred))\n    disc_loss = (disc_fake_loss + disc_real_loss) / 2\n    return disc_loss\ndef get_gen_loss(gen, disc, criterion, num_images, z_dim, device):\n    fake_images = gen(X_oversampled.float().to(device))\n    \n    disc_fake_pred = disc(fake_images)\n    gen_loss = criterion(disc_fake_pred, torch.ones_like(disc_fake_pred))\n    return gen_loss\ny_tr=y_train.ravel()\nli=[]\nfor i in range(len(y_tr)):\n    if int(y_tr[i])==1:\n        li.append(X_train[i])\nX_real=np.array(li)\nt3=X_real.shape\nli2=[1]*(t3[0])\ny_real=np.array(li2)\ny_real.shape\nfrom torch.utils.data import TensorDataset, DataLoader\ntensor_x = torch.Tensor(X_real) \ntensor_y = torch.Tensor(y_real)\nmy_dataset = TensorDataset(tensor_x,tensor_y) # create your datset\ndataloader = DataLoader(\n    my_dataset,\n    batch_size=batch_size,\n    shuffle=True)\ncur_step = 0\nmean_generator_loss = 0\nmean_discriminator_loss = 0\ntest_generator = True \ngen_loss = False\nerror = False\nfor epoch in range(n_epochs):\n  \n    # Dataloader returns the batches\n    for real, _ in tqdm(dataloader):\n        cur_batch_size = len(real)\n\n        # Flatten the batch of real images from the dataset\n        real = real.view(cur_batch_size, -1).to(device)\n\n        ### Update discriminator ###\n        # Zero out the gradients before backpropagation\n        disc_opt.zero_grad()\n\n        # Calculate discriminator loss\n        disc_loss = get_disc_loss(gen, disc, criterion, real, device)\n\n        # Update gradients#\n        disc_loss.backward(retain_graph=True)\n\n        # Update optimizer\n        disc_opt.step()\n\n        # For testing purposes, to keep track of the generator weights\n        if test_generator:\n            old_generator_weights = gen.gen[0][0].weight.detach().clone()\n\n        gen_opt.zero_grad()\n        gen_loss = get_gen_loss(gen, disc, criterion, cur_batch_size, z_dim, device)\n        gen_loss.backward()\n        gen_opt.step()        \n        #### END CODE HERE ####\n\n        # For testing purposes, to check that your code changes the generator weights\n        if test_generator:\n            try:\n                assert lr > 0.0000002 or (gen.gen[0][0].weight.grad.abs().max() < 0.0005 and epoch == 0)\n                assert torch.any(gen.gen[0][0].weight.detach().clone() != old_generator_weights)\n            except:\n                error = True\n                print(\"Runtime tests have failed\")\n\n        # Keep track of the average discriminator loss\n        mean_discriminator_loss += disc_loss.item() / display_step\n\n        # Keep track of the average generator loss\n        mean_generator_loss += gen_loss.item() / display_step\n\n        ### Visualization code ###\n        if cur_step % display_step == 0 and cur_step > 0:\n            print(f\"Epoch {epoch}, step {cur_step}: Generator loss: {mean_generator_loss}, discriminator loss: {mean_discriminator_loss}\")\n            mean_generator_loss = 0\n            mean_discriminator_loss = 0\n        cur_step += 1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res=gen(X_oversampled.float().to(device))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_oversampled","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fres=res.cpu().detach().numpy()\nfres.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tu=X_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fin=np.concatenate((X_train_res[:(tu[0])], fres), axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def shuffle_in_unison(a, b):\n    assert len(a) == len(b)\n    shuffled_a = np.empty(a.shape, dtype=a.dtype)\n    shuffled_b = np.empty(b.shape, dtype=b.dtype)\n    permutation = np.random.permutation(len(a))\n    for old_index, new_index in enumerate(permutation):\n        shuffled_a[new_index] = a[old_index]\n        shuffled_b[new_index] = b[old_index]\n    return shuffled_a, shuffled_b","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_res.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xn,yn=shuffle_in_unison(fin, y_train_res)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ste3=[]\nsta3=[]\nsf3=[]\nfor i in range(30):\n    r=callf1(Xn, yn.ravel(),X_test,  y_test.ravel())\n    ste3.append(r[0])\n    sta3.append(r[1])\n    sf3.append(r[2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(sf3)/30","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(sta3)/30","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum(ste3)/30","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(sf3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(sta3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max(ste3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stdev(sf3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stdev(sta3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stdev(ste3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"progress=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save=2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}